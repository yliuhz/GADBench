{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "# from pygod.utils import load_data\n",
    "import pandas\n",
    "import bidict\n",
    "from dgl.data import FraudAmazonDataset, FraudYelpDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def set_seed(seed=3407):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, name='tfinance', homo=True, add_self_loop=True, to_bidirectional=False, to_simple=True):\n",
    "        if name == 'yelp':\n",
    "            dataset = FraudYelpDataset()\n",
    "            graph = dataset[0]\n",
    "            graph.ndata['train_mask'] = graph.ndata['train_mask'].bool()\n",
    "            graph.ndata['val_mask'] = graph.ndata['val_mask'].bool()\n",
    "            graph.ndata['test_mask'] = graph.ndata['test_mask'].bool()\n",
    "            if homo:\n",
    "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
    "\n",
    "        elif name == 'amazon':\n",
    "            dataset = FraudAmazonDataset()\n",
    "            graph = dataset[0]\n",
    "            graph.ndata['train_mask'] = graph.ndata['train_mask'].bool()\n",
    "            graph.ndata['val_mask'] = graph.ndata['val_mask'].bool()\n",
    "            graph.ndata['test_mask'] = graph.ndata['test_mask'].bool()\n",
    "            graph.ndata['mark'] = graph.ndata['train_mask']+graph.ndata['val_mask']+graph.ndata['test_mask']\n",
    "            if homo:\n",
    "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask', 'mark'])\n",
    "\n",
    "        else:\n",
    "            graph = dgl.load_graphs('datasets/'+name)[0][0]\n",
    "        graph.ndata['feature'] = graph.ndata['feature'].float()\n",
    "        graph.ndata['label'] = graph.ndata['label'].long()\n",
    "        self.name = name\n",
    "        self.graph = graph\n",
    "        if add_self_loop:\n",
    "            self.graph = dgl.add_self_loop(self.graph)\n",
    "        if to_bidirectional:\n",
    "            self.graph = dgl.to_bidirected(self.graph, copy_ndata=True)\n",
    "        if to_simple:\n",
    "            self.graph = dgl.to_simple(self.graph)\n",
    "\n",
    "    def split(self, samples=20):\n",
    "        labels = self.graph.ndata['label']\n",
    "        n = self.graph.num_nodes()\n",
    "        if 'mark' in self.graph.ndata:\n",
    "            index = self.graph.ndata['mark'].nonzero()[:,0].numpy().tolist()\n",
    "        else:\n",
    "            index = list(range(n))\n",
    "        train_masks = torch.zeros([n,20]).bool()\n",
    "        val_masks = torch.zeros([n,20]).bool()\n",
    "        test_masks = torch.zeros([n,20]).bool()\n",
    "        if self.name in ['tolokers', 'questions']:\n",
    "            train_ratio, val_ratio = 0.5, 0.25\n",
    "        if self.name in ['tsocial', 'tfinance', 'reddit', 'weibo']:\n",
    "            train_ratio, val_ratio = 0.4, 0.2\n",
    "        if self.name in ['amazon', 'yelp', 'elliptic', 'dgraphfin']:  # official split\n",
    "            train_masks[:,:10] = self.graph.ndata['train_mask'].repeat(10,1).T\n",
    "            val_masks[:,:10] = self.graph.ndata['val_mask'].repeat(10,1).T\n",
    "            test_masks[:,:10] = self.graph.ndata['test_mask'].repeat(10,1).T\n",
    "        else:\n",
    "            for i in range(10):\n",
    "                seed = 3407+10*i\n",
    "                set_seed(seed)\n",
    "                idx_train, idx_rest, y_train, y_rest = train_test_split(index, labels[index], stratify=labels[index], train_size=train_ratio, random_state=seed, shuffle=True)\n",
    "                idx_valid, idx_test, y_valid, y_test = train_test_split(idx_rest, y_rest, stratify=y_rest, train_size=int(len(index)*val_ratio), random_state=seed, shuffle=True)\n",
    "                train_masks[idx_train,i] = 1\n",
    "                val_masks[idx_valid,i] = 1\n",
    "                test_masks[idx_test,i] = 1\n",
    "\n",
    "        for i in range(10):\n",
    "            pos_index = np.where(labels == 1)[0]\n",
    "            neg_index = list(set(index) - set(pos_index))\n",
    "            pos_train_idx = np.random.choice(pos_index, size=2*samples, replace=False)\n",
    "            neg_train_idx = np.random.choice(neg_index, size=8*samples, replace=False)\n",
    "            train_idx = np.concatenate([pos_train_idx[:samples], neg_train_idx[:4*samples]])\n",
    "            train_masks[train_idx, 10+i] = 1\n",
    "            val_idx = np.concatenate([pos_train_idx[samples:], neg_train_idx[4*samples:]])\n",
    "            val_masks[val_idx, 10+i] = 1\n",
    "            test_masks[index, 10+i] = 1\n",
    "            test_masks[train_idx, 10+i] = 0\n",
    "            test_masks[val_idx, 10+i] = 0\n",
    "\n",
    "        self.graph.ndata['train_masks'] = train_masks\n",
    "        self.graph.ndata['val_masks'] = val_masks\n",
    "        self.graph.ndata['test_masks'] = test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24200 5694 16670\n",
      "Graph(num_nodes=203769, num_edges=438124,\n",
      "      ndata_schemes={'feature': Scheme(shape=(166,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'mark': Scheme(shape=(), dtype=torch.uint8), 'test_mask': Scheme(shape=(), dtype=torch.uint8), 'val_mask': Scheme(shape=(), dtype=torch.uint8), 'train_mask': Scheme(shape=(), dtype=torch.uint8), 'train_masks': Scheme(shape=(20,), dtype=torch.bool), 'val_masks': Scheme(shape=(20,), dtype=torch.bool), 'test_masks': Scheme(shape=(20,), dtype=torch.bool)}\n",
      "      edata_schemes={'count': Scheme(shape=(), dtype=torch.int64)})\n",
      "tensor([24200, 24200, 24200, 24200, 24200, 24200, 24200, 24200, 24200, 24200,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100]) tensor([5694, 5694, 5694, 5694, 5694, 5694, 5694, 5694, 5694, 5694,  100,  100,\n",
      "         100,  100,  100,  100,  100,  100,  100,  100]) tensor([16670, 16670, 16670, 16670, 16670, 16670, 16670, 16670, 16670, 16670,\n",
      "        46364, 46364, 46364, 46364, 46364, 46364, 46364, 46364, 46364, 46364])\n",
      "Graph(num_nodes=3700550, num_edges=8001549,\n",
      "      ndata_schemes={'mark': Scheme(shape=(), dtype=torch.uint8), 'test_mask': Scheme(shape=(), dtype=torch.uint8), 'val_mask': Scheme(shape=(), dtype=torch.uint8), 'train_mask': Scheme(shape=(), dtype=torch.uint8), 'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(17,), dtype=torch.float32), 'train_masks': Scheme(shape=(20,), dtype=torch.bool), 'val_masks': Scheme(shape=(20,), dtype=torch.bool), 'test_masks': Scheme(shape=(20,), dtype=torch.bool)}\n",
      "      edata_schemes={'count': Scheme(shape=(), dtype=torch.int64)})\n",
      "tensor([857899, 857899, 857899, 857899, 857899, 857899, 857899, 857899, 857899,\n",
      "        857899,    100,    100,    100,    100,    100,    100,    100,    100,\n",
      "           100,    100]) tensor([183862, 183862, 183862, 183862, 183862, 183862, 183862, 183862, 183862,\n",
      "        183862,    100,    100,    100,    100,    100,    100,    100,    100,\n",
      "           100,    100]) tensor([ 183840,  183840,  183840,  183840,  183840,  183840,  183840,  183840,\n",
      "         183840,  183840, 1225401, 1225401, 1225401, 1225401, 1225401, 1225401,\n",
      "        1225401, 1225401, 1225401, 1225401])\n"
     ]
    }
   ],
   "source": [
    "# preprocess elliptic\n",
    "labels = pandas.read_csv('datasets/elliptic_bitcoin_dataset/elliptic_txs_classes.csv').to_numpy()\n",
    "node_features = pandas.read_csv('datasets/elliptic_bitcoin_dataset/elliptic_txs_features.csv', header=None).to_numpy()\n",
    "\n",
    "node_dict = bidict.bidict()\n",
    "\n",
    "for i in range(labels.shape[0]):\n",
    "    node_dict[i] = labels[i][0]\n",
    "\n",
    "new_labels = np.zeros(labels.shape[0]).astype(int)\n",
    "marks = labels[:,1]!='unknown'\n",
    "features = node_features[:,1:]\n",
    "new_labels[labels[:,1]=='1']=1\n",
    "\n",
    "train_mask = (features[:,0]<=25)&marks\n",
    "val_mask = (features[:,0]>25)&(features[:,0]<=34)&marks\n",
    "test_mask = (features[:,0]>34)&marks\n",
    "print(train_mask.sum(), val_mask.sum(), test_mask.sum())\n",
    "edges = pandas.read_csv('datasets/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv').to_numpy()\n",
    "\n",
    "new_edges = np.zeros_like(edges)\n",
    "\n",
    "for i in range(edges.shape[0]):\n",
    "    new_edges[i][0] = node_dict.inv[edges[i][0]]\n",
    "    new_edges[i][1] = node_dict.inv[edges[i][1]]\n",
    "\n",
    "graph = dgl.graph((new_edges[:,0], new_edges[:,1]))\n",
    "graph.ndata['train_mask'] = torch.tensor(train_mask).bool()\n",
    "graph.ndata['val_mask'] = torch.tensor(val_mask).bool()\n",
    "graph.ndata['test_mask'] = torch.tensor(test_mask).bool()\n",
    "graph.ndata['mark'] = torch.tensor(marks).bool()\n",
    "graph.ndata['label'] = torch.tensor(new_labels)\n",
    "graph.ndata['feature'] = torch.tensor(features)\n",
    "\n",
    "dgl.save_graphs('datasets/elliptic', [graph])\n",
    "\n",
    "\n",
    "# preprocess dgraphfin\n",
    "f = np.load('datasets/dgraphfin.npz')\n",
    "x = torch.tensor(f['x']).float()\n",
    "y = torch.tensor(f['y']).float()\n",
    "y = (y == 1).int()\n",
    "g = dgl.graph((f['edge_index'][:,0], f['edge_index'][:,1]))\n",
    "\n",
    "g.ndata['feature'] = x\n",
    "g.ndata['label'] = y\n",
    "\n",
    "g.ndata['train_mask'] = torch.zeros_like(y).bool()\n",
    "g.ndata['val_mask'] = torch.zeros_like(y).bool()\n",
    "g.ndata['test_mask'] = torch.zeros_like(y).bool()\n",
    "\n",
    "g.ndata['train_mask'][list(f['train_mask'])] = True\n",
    "g.ndata['val_mask'][list(f['valid_mask'])] = True\n",
    "g.ndata['test_mask'][list(f['test_mask'])] = True\n",
    "g.ndata['mark'] = (g.ndata['train_mask']+g.ndata['val_mask']+g.ndata['test_mask']).bool()\n",
    "dgl.save_graphs('datasets/dgraphfin', [g])\n",
    "\n",
    "# split dgraphfin and elliptic\n",
    "for data_name in ['elliptic', 'dgraphfin']:\n",
    "    data = Dataset(data_name)\n",
    "    data.split()\n",
    "    print(data.graph)\n",
    "    print(data.graph.ndata['train_masks'].sum(0), data.graph.ndata['val_masks'].sum(0), data.graph.ndata['test_masks'].sum(0))\n",
    "    dgl.save_graphs('datasets/'+data_name, [data.graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the following code is just for reference and not needed for the experiments if you have downloaded the datasets\n",
    "\n",
    "# preprocess reddit / amazon\n",
    "# data = load_data('reddit','data-main')\n",
    "# graph = dgl.graph((data.edge_index[0,:], data.edge_index[1,:]))\n",
    "# graph.ndata['feature'] = data.x\n",
    "# graph.ndata['label'] = data.y\n",
    "# graph.ndata['label'].sum()\n",
    "# dgl.save_graphs('reddit', [graph])\n",
    "\n",
    "# preprocess t-social\n",
    "# g = dgl.load_graphs('data/tsocial')[0][0]\n",
    "# g = dgl.to_homogeneous(g, ['feature', 'label', 'train_masks', 'val_masks', 'test_masks'])\n",
    "# dgl.save_graphs('data/tsocial', [g])\n",
    "\n",
    "# split all datasets\n",
    "# for data_name in ['amazon', 'yelp', 'elliptic', 'dgraphfin','tolokers', 'questions', 'tsocial', 'tfinance', 'reddit', 'weibo']:\n",
    "#     data = Dataset(data_name)\n",
    "#     data.split()\n",
    "#     print(data.graph)\n",
    "#     print(data.graph.ndata['train_masks'].sum(0), data.graph.ndata['val_masks'].sum(0), data.graph.ndata['test_masks'].sum(0))\n",
    "#     dgl.save_graphs(data_name, [data.graph])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
