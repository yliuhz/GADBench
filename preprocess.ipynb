{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "# from pygod.utils import load_data\n",
    "import pandas\n",
    "import bidict\n",
    "from dgl.data import FraudAmazonDataset, FraudYelpDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def set_seed(seed=3407):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, name='tfinance', homo=True, add_self_loop=True, to_bidirectional=False, to_simple=True):\n",
    "        if name == 'yelp':\n",
    "            dataset = FraudYelpDataset()\n",
    "            graph = dataset[0]\n",
    "            graph.ndata['train_mask'] = graph.ndata['train_mask'].bool()\n",
    "            graph.ndata['val_mask'] = graph.ndata['val_mask'].bool()\n",
    "            graph.ndata['test_mask'] = graph.ndata['test_mask'].bool()\n",
    "            if homo:\n",
    "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
    "\n",
    "        elif name == 'amazon':\n",
    "            dataset = FraudAmazonDataset()\n",
    "            graph = dataset[0]\n",
    "            graph.ndata['train_mask'] = graph.ndata['train_mask'].bool()\n",
    "            graph.ndata['val_mask'] = graph.ndata['val_mask'].bool()\n",
    "            graph.ndata['test_mask'] = graph.ndata['test_mask'].bool()\n",
    "            graph.ndata['mark'] = graph.ndata['train_mask']+graph.ndata['val_mask']+graph.ndata['test_mask']\n",
    "            if homo:\n",
    "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask', 'mark'])\n",
    "\n",
    "        else:\n",
    "            graph = dgl.load_graphs('datasets/'+name)[0][0]\n",
    "        graph.ndata['feature'] = graph.ndata['feature'].float()\n",
    "        graph.ndata['label'] = graph.ndata['label'].long()\n",
    "        self.name = name\n",
    "        self.graph = graph\n",
    "        if add_self_loop:\n",
    "            self.graph = dgl.add_self_loop(self.graph)\n",
    "        if to_bidirectional:\n",
    "            self.graph = dgl.to_bidirected(self.graph, copy_ndata=True)\n",
    "        if to_simple:\n",
    "            self.graph = dgl.to_simple(self.graph)\n",
    "\n",
    "    def split(self, samples=20):\n",
    "        labels = self.graph.ndata['label']\n",
    "        n = self.graph.num_nodes()\n",
    "        if 'mark' in self.graph.ndata:\n",
    "            index = self.graph.ndata['mark'].nonzero()[:,0].numpy().tolist()\n",
    "        else:\n",
    "            index = list(range(n))\n",
    "        train_masks = torch.zeros([n,20]).bool()\n",
    "        val_masks = torch.zeros([n,20]).bool()\n",
    "        test_masks = torch.zeros([n,20]).bool()\n",
    "        if self.name in ['tolokers', 'questions']:\n",
    "            train_ratio, val_ratio = 0.5, 0.25\n",
    "        if self.name in ['tsocial', 'tfinance', 'reddit', 'weibo']:\n",
    "            train_ratio, val_ratio = 0.4, 0.2\n",
    "        if self.name in ['amazon', 'yelp', 'elliptic', 'dgraphfin']:  # official split\n",
    "            train_masks[:,:10] = self.graph.ndata['train_mask'].repeat(10,1).T\n",
    "            val_masks[:,:10] = self.graph.ndata['val_mask'].repeat(10,1).T\n",
    "            test_masks[:,:10] = self.graph.ndata['test_mask'].repeat(10,1).T\n",
    "        else:\n",
    "            for i in range(10):\n",
    "                seed = 3407+10*i\n",
    "                set_seed(seed)\n",
    "                idx_train, idx_rest, y_train, y_rest = train_test_split(index, labels[index], stratify=labels[index], train_size=train_ratio, random_state=seed, shuffle=True)\n",
    "                idx_valid, idx_test, y_valid, y_test = train_test_split(idx_rest, y_rest, stratify=y_rest, train_size=int(len(index)*val_ratio), random_state=seed, shuffle=True)\n",
    "                train_masks[idx_train,i] = 1\n",
    "                val_masks[idx_valid,i] = 1\n",
    "                test_masks[idx_test,i] = 1\n",
    "\n",
    "        for i in range(10):\n",
    "            pos_index = np.where(labels == 1)[0]\n",
    "            neg_index = list(set(index) - set(pos_index))\n",
    "            pos_train_idx = np.random.choice(pos_index, size=2*samples, replace=False)\n",
    "            neg_train_idx = np.random.choice(neg_index, size=8*samples, replace=False)\n",
    "            train_idx = np.concatenate([pos_train_idx[:samples], neg_train_idx[:4*samples]])\n",
    "            train_masks[train_idx, 10+i] = 1\n",
    "            val_idx = np.concatenate([pos_train_idx[samples:], neg_train_idx[4*samples:]])\n",
    "            val_masks[val_idx, 10+i] = 1\n",
    "            test_masks[index, 10+i] = 1\n",
    "            test_masks[train_idx, 10+i] = 0\n",
    "            test_masks[val_idx, 10+i] = 0\n",
    "\n",
    "        self.graph.ndata['train_masks'] = train_masks\n",
    "        self.graph.ndata['val_masks'] = val_masks\n",
    "        self.graph.ndata['test_masks'] = test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24200 5694 16670\n",
      "Graph(num_nodes=203769, num_edges=438124,\n",
      "      ndata_schemes={'feature': Scheme(shape=(166,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'mark': Scheme(shape=(), dtype=torch.uint8), 'test_mask': Scheme(shape=(), dtype=torch.uint8), 'val_mask': Scheme(shape=(), dtype=torch.uint8), 'train_mask': Scheme(shape=(), dtype=torch.uint8), 'train_masks': Scheme(shape=(20,), dtype=torch.bool), 'val_masks': Scheme(shape=(20,), dtype=torch.bool), 'test_masks': Scheme(shape=(20,), dtype=torch.bool)}\n",
      "      edata_schemes={'count': Scheme(shape=(), dtype=torch.int64)})\n",
      "tensor([24200, 24200, 24200, 24200, 24200, 24200, 24200, 24200, 24200, 24200,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100]) tensor([5694, 5694, 5694, 5694, 5694, 5694, 5694, 5694, 5694, 5694,  100,  100,\n",
      "         100,  100,  100,  100,  100,  100,  100,  100]) tensor([16670, 16670, 16670, 16670, 16670, 16670, 16670, 16670, 16670, 16670,\n",
      "        46364, 46364, 46364, 46364, 46364, 46364, 46364, 46364, 46364, 46364])\n",
      "Graph(num_nodes=3700550, num_edges=8001549,\n",
      "      ndata_schemes={'mark': Scheme(shape=(), dtype=torch.uint8), 'test_mask': Scheme(shape=(), dtype=torch.uint8), 'val_mask': Scheme(shape=(), dtype=torch.uint8), 'train_mask': Scheme(shape=(), dtype=torch.uint8), 'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(17,), dtype=torch.float32), 'train_masks': Scheme(shape=(20,), dtype=torch.bool), 'val_masks': Scheme(shape=(20,), dtype=torch.bool), 'test_masks': Scheme(shape=(20,), dtype=torch.bool)}\n",
      "      edata_schemes={'count': Scheme(shape=(), dtype=torch.int64)})\n",
      "tensor([857899, 857899, 857899, 857899, 857899, 857899, 857899, 857899, 857899,\n",
      "        857899,    100,    100,    100,    100,    100,    100,    100,    100,\n",
      "           100,    100]) tensor([183862, 183862, 183862, 183862, 183862, 183862, 183862, 183862, 183862,\n",
      "        183862,    100,    100,    100,    100,    100,    100,    100,    100,\n",
      "           100,    100]) tensor([ 183840,  183840,  183840,  183840,  183840,  183840,  183840,  183840,\n",
      "         183840,  183840, 1225401, 1225401, 1225401, 1225401, 1225401, 1225401,\n",
      "        1225401, 1225401, 1225401, 1225401])\n"
     ]
    }
   ],
   "source": [
    "# preprocess elliptic\n",
    "labels = pandas.read_csv('datasets/elliptic_bitcoin_dataset/elliptic_txs_classes.csv').to_numpy()\n",
    "node_features = pandas.read_csv('datasets/elliptic_bitcoin_dataset/elliptic_txs_features.csv', header=None).to_numpy()\n",
    "\n",
    "node_dict = bidict.bidict()\n",
    "\n",
    "for i in range(labels.shape[0]):\n",
    "    node_dict[i] = labels[i][0]\n",
    "\n",
    "new_labels = np.zeros(labels.shape[0]).astype(int)\n",
    "marks = labels[:,1]!='unknown'\n",
    "features = node_features[:,1:]\n",
    "new_labels[labels[:,1]=='1']=1\n",
    "\n",
    "train_mask = (features[:,0]<=25)&marks\n",
    "val_mask = (features[:,0]>25)&(features[:,0]<=34)&marks\n",
    "test_mask = (features[:,0]>34)&marks\n",
    "print(train_mask.sum(), val_mask.sum(), test_mask.sum())\n",
    "edges = pandas.read_csv('datasets/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv').to_numpy()\n",
    "\n",
    "new_edges = np.zeros_like(edges)\n",
    "\n",
    "for i in range(edges.shape[0]):\n",
    "    new_edges[i][0] = node_dict.inv[edges[i][0]]\n",
    "    new_edges[i][1] = node_dict.inv[edges[i][1]]\n",
    "\n",
    "graph = dgl.graph((new_edges[:,0], new_edges[:,1]))\n",
    "graph.ndata['train_mask'] = torch.tensor(train_mask).bool()\n",
    "graph.ndata['val_mask'] = torch.tensor(val_mask).bool()\n",
    "graph.ndata['test_mask'] = torch.tensor(test_mask).bool()\n",
    "graph.ndata['mark'] = torch.tensor(marks).bool()\n",
    "graph.ndata['label'] = torch.tensor(new_labels)\n",
    "graph.ndata['feature'] = torch.tensor(features)\n",
    "\n",
    "dgl.save_graphs('datasets/elliptic', [graph])\n",
    "\n",
    "\n",
    "# preprocess dgraphfin\n",
    "f = np.load('datasets/dgraphfin.npz')\n",
    "x = torch.tensor(f['x']).float()\n",
    "y = torch.tensor(f['y']).float()\n",
    "y = (y == 1).int()\n",
    "g = dgl.graph((f['edge_index'][:,0], f['edge_index'][:,1]))\n",
    "\n",
    "g.ndata['feature'] = x\n",
    "g.ndata['label'] = y\n",
    "\n",
    "g.ndata['train_mask'] = torch.zeros_like(y).bool()\n",
    "g.ndata['val_mask'] = torch.zeros_like(y).bool()\n",
    "g.ndata['test_mask'] = torch.zeros_like(y).bool()\n",
    "\n",
    "g.ndata['train_mask'][list(f['train_mask'])] = True\n",
    "g.ndata['val_mask'][list(f['valid_mask'])] = True\n",
    "g.ndata['test_mask'][list(f['test_mask'])] = True\n",
    "g.ndata['mark'] = (g.ndata['train_mask']+g.ndata['val_mask']+g.ndata['test_mask']).bool()\n",
    "dgl.save_graphs('datasets/dgraphfin', [g])\n",
    "\n",
    "# split dgraphfin and elliptic\n",
    "for data_name in ['elliptic', 'dgraphfin']:\n",
    "    data = Dataset(data_name)\n",
    "    data.split()\n",
    "    print(data.graph)\n",
    "    print(data.graph.ndata['train_masks'].sum(0), data.graph.ndata['val_masks'].sum(0), data.graph.ndata['test_masks'].sum(0))\n",
    "    dgl.save_graphs('datasets/'+data_name, [data.graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the following code is just for reference and not needed for the experiments if you have downloaded the datasets\n",
    "\n",
    "# preprocess reddit / amazon\n",
    "# data = load_data('reddit','data-main')\n",
    "# graph = dgl.graph((data.edge_index[0,:], data.edge_index[1,:]))\n",
    "# graph.ndata['feature'] = data.x\n",
    "# graph.ndata['label'] = data.y\n",
    "# graph.ndata['label'].sum()\n",
    "# dgl.save_graphs('reddit', [graph])\n",
    "\n",
    "# preprocess t-social\n",
    "# g = dgl.load_graphs('data/tsocial')[0][0]\n",
    "# g = dgl.to_homogeneous(g, ['feature', 'label', 'train_masks', 'val_masks', 'test_masks'])\n",
    "# dgl.save_graphs('data/tsocial', [g])\n",
    "\n",
    "# split all datasets\n",
    "# for data_name in ['amazon', 'yelp', 'elliptic', 'dgraphfin','tolokers', 'questions', 'tsocial', 'tfinance', 'reddit', 'weibo']:\n",
    "#     data = Dataset(data_name)\n",
    "#     data.split()\n",
    "#     print(data.graph)\n",
    "#     print(data.graph.ndata['train_masks'].sum(0), data.graph.ndata['val_masks'].sum(0), data.graph.ndata['test_masks'].sum(0))\n",
    "#     dgl.save_graphs(data_name, [data.graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print train/val/test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from models.detector import *\n",
    "from dgl.data.utils import load_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, name='tfinance', prefix='datasets/'):\n",
    "        graph = load_graphs(prefix + name)[0][0]\n",
    "        self.name = name\n",
    "        self.graph = graph\n",
    "\n",
    "    def split(self, semi_supervised=True, trial_id=0):\n",
    "        if semi_supervised:\n",
    "            trial_id += 10\n",
    "        self.graph.ndata['train_mask'] = self.graph.ndata['train_masks'][:,trial_id]\n",
    "        self.graph.ndata['val_mask'] = self.graph.ndata['val_masks'][:,trial_id]\n",
    "        self.graph.ndata['test_mask'] = self.graph.ndata['test_masks'][:,trial_id]\n",
    "#         print(self.graph.ndata['train_mask'].sum(), self.graph.ndata['val_mask'].sum(), self.graph.ndata['test_mask'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['reddit', 'weibo', 'amazon', 'yelp', 'tfinance',\n",
    "            'elliptic', 'tolokers', 'questions', 'dgraphfin', 'tsocial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\"Datasets\": datasets}, columns=[\"Datasets\", \"#Nodes\", \"#Edges\", \"#Train\", \"#Val\", \"#Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretty(styler, caption, precision):\n",
    "    styler.set_caption(f\"{caption}\")\n",
    "#     styler.format(rain_condition)\n",
    "#     styler.format_index(lambda v: v.strftime(\"%A\"))\n",
    "#     styler.format(precision=precision)\n",
    "#     styler.highlight_max(subset=datasets ,color = 'pink', axis = 0)\n",
    "#     styler.background_gradient(axis=None, vmin=1, vmax=5, cmap=\"YlGnBu\")\n",
    "    return styler\n",
    "def show_df_results(df, caption, precision):\n",
    "    return df.style.pipe(make_pretty, caption, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit\n",
      "weibo\n",
      "amazon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp\n",
      "tfinance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elliptic\n",
      "tolokers\n",
      "questions\n",
      "dgraphfin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsocial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2083991/1779923639.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Nodes\"][d_idx] = n\n",
      "/tmp/ipykernel_2083991/1779923639.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Edges\"][d_idx] = m\n",
      "/tmp/ipykernel_2083991/1779923639.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
      "/tmp/ipykernel_2083991/1779923639.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n"
     ]
    }
   ],
   "source": [
    "semi_supervised = True\n",
    "for d_idx, dataset in enumerate(datasets):\n",
    "    print(dataset)\n",
    "    \n",
    "    data = Dataset(dataset, prefix=dataroot)\n",
    "    data.split(semi_supervised=semi_supervised)\n",
    "    graph = data.graph\n",
    "#     print(data.graph)\n",
    "    labels = graph.ndata[\"label\"]\n",
    "    \n",
    "    train_mask = data.graph.ndata['train_mask'].bool()\n",
    "    val_mask = data.graph.ndata['val_mask'].bool()\n",
    "    test_mask = data.graph.ndata['test_mask'].bool()\n",
    "    \n",
    "    \n",
    "#     print(data.graph.ndata['train_mask'].sum(), data.graph.ndata['val_mask'].sum(), data.graph.ndata['test_mask'].sum())\n",
    "    n, m = graph.number_of_nodes(), graph.number_of_edges()\n",
    "    df_results[\"#Nodes\"][d_idx] = n\n",
    "    df_results[\"#Edges\"][d_idx] = m\n",
    "    \n",
    "    train_labels_positive_ratio = (labels[train_mask]==1).sum() / len(labels[train_mask]) * 100\n",
    "    val_labels_positive_ratio = (labels[val_mask]==1).sum() / len(labels[val_mask]) * 100\n",
    "    test_labels_positive_ratio = (labels[test_mask]==1).sum() / len(labels[test_mask]) * 100\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_results[\"#Train\"][d_idx] = f\"{train_mask.sum().item()} ({train_mask.sum().item()/n*100:.0f}%, {train_labels_positive_ratio:.0f}%)\"\n",
    "    df_results[\"#Val\"][d_idx] = f\"{val_mask.sum().item()} ({val_mask.sum().item()/n*100:.0f}%, {val_labels_positive_ratio:.0f}%)\"\n",
    "    df_results[\"#Test\"][d_idx] = f\"{test_mask.sum().item()} ({test_mask.sum().item()/n*100:.0f}%, {test_labels_positive_ratio:.0f}%)\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e1356\">\n",
       "  <caption>Semi Supervised</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e1356_level0_col0\" class=\"col_heading level0 col0\" >Datasets</th>\n",
       "      <th id=\"T_e1356_level0_col1\" class=\"col_heading level0 col1\" >#Nodes</th>\n",
       "      <th id=\"T_e1356_level0_col2\" class=\"col_heading level0 col2\" >#Edges</th>\n",
       "      <th id=\"T_e1356_level0_col3\" class=\"col_heading level0 col3\" >#Train</th>\n",
       "      <th id=\"T_e1356_level0_col4\" class=\"col_heading level0 col4\" >#Val</th>\n",
       "      <th id=\"T_e1356_level0_col5\" class=\"col_heading level0 col5\" >#Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e1356_row0_col0\" class=\"data row0 col0\" >reddit</td>\n",
       "      <td id=\"T_e1356_row0_col1\" class=\"data row0 col1\" >10984</td>\n",
       "      <td id=\"T_e1356_row0_col2\" class=\"data row0 col2\" >168016</td>\n",
       "      <td id=\"T_e1356_row0_col3\" class=\"data row0 col3\" >100 (1%, 20%)</td>\n",
       "      <td id=\"T_e1356_row0_col4\" class=\"data row0 col4\" >100 (1%, 20%)</td>\n",
       "      <td id=\"T_e1356_row0_col5\" class=\"data row0 col5\" >10784 (98%, 3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e1356_row1_col0\" class=\"data row1 col0\" >weibo</td>\n",
       "      <td id=\"T_e1356_row1_col1\" class=\"data row1 col1\" >8405</td>\n",
       "      <td id=\"T_e1356_row1_col2\" class=\"data row1 col2\" >416368</td>\n",
       "      <td id=\"T_e1356_row1_col3\" class=\"data row1 col3\" >100 (1%, 20%)</td>\n",
       "      <td id=\"T_e1356_row1_col4\" class=\"data row1 col4\" >100 (1%, 20%)</td>\n",
       "      <td id=\"T_e1356_row1_col5\" class=\"data row1 col5\" >8205 (98%, 10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e1356_row2_col0\" class=\"data row2 col0\" >amazon</td>\n",
       "      <td id=\"T_e1356_row2_col1\" class=\"data row2 col1\" >11944</td>\n",
       "      <td id=\"T_e1356_row2_col2\" class=\"data row2 col2\" >8847096</td>\n",
       "      <td id=\"T_e1356_row2_col3\" class=\"data row2 col3\" >100 (1%, 20%)</td>\n",
       "      <td id=\"T_e1356_row2_col4\" class=\"data row2 col4\" >100 (1%, 20%)</td>\n",
       "      <td id=\"T_e1356_row2_col5\" class=\"data row2 col5\" >8439 (71%, 9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e1356_row3_col0\" class=\"data row3 col0\" >yelp</td>\n",
       "      <td id=\"T_e1356_row3_col1\" class=\"data row3 col1\" >45954</td>\n",
       "      <td id=\"T_e1356_row3_col2\" class=\"data row3 col2\" >7739912</td>\n",
       "      <td id=\"T_e1356_row3_col3\" class=\"data row3 col3\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row3_col4\" class=\"data row3 col4\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row3_col5\" class=\"data row3 col5\" >45754 (100%, 15%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e1356_row4_col0\" class=\"data row4 col0\" >tfinance</td>\n",
       "      <td id=\"T_e1356_row4_col1\" class=\"data row4 col1\" >39357</td>\n",
       "      <td id=\"T_e1356_row4_col2\" class=\"data row4 col2\" >42484443</td>\n",
       "      <td id=\"T_e1356_row4_col3\" class=\"data row4 col3\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row4_col4\" class=\"data row4 col4\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row4_col5\" class=\"data row4 col5\" >39157 (99%, 5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e1356_row5_col0\" class=\"data row5 col0\" >elliptic</td>\n",
       "      <td id=\"T_e1356_row5_col1\" class=\"data row5 col1\" >203769</td>\n",
       "      <td id=\"T_e1356_row5_col2\" class=\"data row5 col2\" >438124</td>\n",
       "      <td id=\"T_e1356_row5_col3\" class=\"data row5 col3\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row5_col4\" class=\"data row5 col4\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row5_col5\" class=\"data row5 col5\" >46364 (23%, 10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e1356_row6_col0\" class=\"data row6 col0\" >tolokers</td>\n",
       "      <td id=\"T_e1356_row6_col1\" class=\"data row6 col1\" >11758</td>\n",
       "      <td id=\"T_e1356_row6_col2\" class=\"data row6 col2\" >530758</td>\n",
       "      <td id=\"T_e1356_row6_col3\" class=\"data row6 col3\" >100 (1%, 20%)</td>\n",
       "      <td id=\"T_e1356_row6_col4\" class=\"data row6 col4\" >100 (1%, 20%)</td>\n",
       "      <td id=\"T_e1356_row6_col5\" class=\"data row6 col5\" >11558 (98%, 22%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e1356_row7_col0\" class=\"data row7 col0\" >questions</td>\n",
       "      <td id=\"T_e1356_row7_col1\" class=\"data row7 col1\" >48921</td>\n",
       "      <td id=\"T_e1356_row7_col2\" class=\"data row7 col2\" >202461</td>\n",
       "      <td id=\"T_e1356_row7_col3\" class=\"data row7 col3\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row7_col4\" class=\"data row7 col4\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row7_col5\" class=\"data row7 col5\" >48721 (100%, 3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e1356_row8_col0\" class=\"data row8 col0\" >dgraphfin</td>\n",
       "      <td id=\"T_e1356_row8_col1\" class=\"data row8 col1\" >3700550</td>\n",
       "      <td id=\"T_e1356_row8_col2\" class=\"data row8 col2\" >8001549</td>\n",
       "      <td id=\"T_e1356_row8_col3\" class=\"data row8 col3\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row8_col4\" class=\"data row8 col4\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row8_col5\" class=\"data row8 col5\" >1225401 (33%, 1%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1356_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e1356_row9_col0\" class=\"data row9 col0\" >tsocial</td>\n",
       "      <td id=\"T_e1356_row9_col1\" class=\"data row9 col1\" >5781065</td>\n",
       "      <td id=\"T_e1356_row9_col2\" class=\"data row9 col2\" >151992081</td>\n",
       "      <td id=\"T_e1356_row9_col3\" class=\"data row9 col3\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row9_col4\" class=\"data row9 col4\" >100 (0%, 20%)</td>\n",
       "      <td id=\"T_e1356_row9_col5\" class=\"data row9 col5\" >5780865 (100%, 3%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb59acdb8b0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_df_results(df_results, \"Fully Supervised\" if not semi_supervised else \"Semi Supervised\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:autocls]",
   "language": "python",
   "name": "conda-env-autocls-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
